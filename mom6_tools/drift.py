#!/usr/bin/env python

"""
Functions used to calculate the drift of scalars within defined regions and globally.
"""

import xarray as xr
import numpy as np
import matplotlib.pyplot as plt
from mom6_tools.DiagsCase import DiagsCase
from mom6_tools.ClimoGenerator import ClimoGenerator
from mom6_tools.m6toolbox import genBasinMasks, add_global_attrs, weighted_temporal_mean
from mom6_tools.m6plot import ztplot, plot_stats_da, xyplot
from mom6_tools.MOM6grid import MOM6grid
from datetime import datetime
from distributed import Client
from ncar_jobqueue import NCARCluster
from collections import OrderedDict
import yaml, os, intake

try: import argparse
except: raise Exception('This version of python is not new enough. python 2.7 or newer is required.')

def options():
  parser = argparse.ArgumentParser(description='''Compute horizontal drift and/or RMS: model versus \
                      observations.''')
  parser.add_argument('diag_config_yml_path', type=str, help='''Full path to the yaml file  \
    with metadata for the experiment to be processed.''')
  parser.add_argument('var', type=str, help='''Name of variable to be processed.  \
    Currently, only thetao or so are supported.''')
  parser.add_argument('--drift', action='store_true',
                      help='''Compute drift. Default is False''')
  parser.add_argument('--rms', action='store_true',
                      help='''Compute rms. Default is False''')
  parser.add_argument('--savefig', action='store_true',
                      help='''Save figures (PNG). Default is False''')
  parser.add_argument('-nw','--number_of_workers',  type=int, default=0,
                      help='''Number of workers to use. Default=0 (serial).''')
  parser.add_argument('-o','--obs', type=str, default='woa-2018-tx2_3v2-annual-all',
                      help='''Name of observational product in the oce-catalog  \
    to compare against. Default is woa-2018-tx2_3v2-annual-all''')
  parser.add_argument('-debug',   help='''Add priting statements for debugging purposes''', action="store_true")
  cmdLineArgs = parser.parse_args()
  return cmdLineArgs

def HorizontalMeanRmse_da(var, dims=('yh', 'xh'), weights=None, basins=None, debug=False):
  """
  Wrapper for computing weighted horizontal root-mean-square error for DataArrays.
  This function includes the option to provide Basins masks, which returns RMSe
  for each basin provided.

  Parameters
  ----------

  var : xarray.DataArray
    Difference between the actual values and predicted values (model - obs, or residual).

  dims : tuple, str
    Dimensions over which to apply average. Default is ('yh', 'xh').

  weights : xarray.DataArray, optional
      weights to apply. It can be a masked array.

  basins : xarray.DataArray, optional
      Basins mask to apply. If True, returns horizontal mean RMSE for each basin provided. \
      Basins must be generated by genBasinMasks. Default is False.

  debug : boolean, optional
    If true, print stuff for debugging. Default is False.

  Returns
  -------
  reduced : DataArray or DataSet
      If Basins is provided, returns an DataSet with horizontal mean RMS. Otherwise,
       returns a DataArray.
  """
  check_dims(var,dims)

  if basins is not None and weights is None:
    raise ValueError("Basin masks can only be applied if weights are provided.")

  if weights is None:
    return rms_da(var)
  else:
    if basins is None:
      # global reduction
      if not isinstance(weights, xr.DataArray):
        raise ValueError("weights must be a DataArray")

      check_dims(weights, dims)

      total_weights = weights.sum(dim=dims)
      if debug: print('total weights is:', total_weights.values)
      out = rms_da(var, weights=weights, weights_sum=total_weights)
      if debug: print('rmse is:', out.values)

    else:
      # regional reduction
      if 'region' not in basins.coords:
        raise ValueError("Regions does not have coordinate region. Please use genBasinMasks \
                          to construct the basins mask.")
      if len(weights.shape)!=3:
        raise ValueError("If basins is provided, weights must be a 3D array.")

      if len(basins.shape)!=3:
        raise ValueError("Regions must be a 3D array.")

      rmask_od = OrderedDict()
      for reg in basins.region:
        if debug: print('Region: ', reg)
        # construct a 3D region array
        tmp = np.repeat(basins.sel(region=reg).values[np.newaxis, :, :], len(var.z_l), axis=0)
        region3d = xr.DataArray(tmp,dims=var.dims[1::],
                                coords= {var.dims[1]: var.z_l,
                                         var.dims[2]: var.yh,
                                         var.dims[3]: var.xh})
        if debug: print('region3d:', region3d)
        # select weights to where region3d is one
        tmp_weights = weights.where(region3d == 1.0)
        total_weights = tmp_weights.sum(dim=dims)
        if debug: print('total weights is:', total_weights.values)
        rmask_od[str(reg.values)] = rms_da(var, weights=tmp_weights, weights_sum=total_weights)

        if debug: print('rms is:', rmask_od[str(reg.values)])
      # create DataArray to store output
      out = xr.DataArray(np.zeros((len(basins.region), var.shape[0], var.shape[1])),
                         dims=(basins.dims[0], var.dims[0], var.dims[1]),
                         coords={basins.dims[0]:list(rmask_od.keys()),
                                 var.dims[0]: var.time,
                                 var.dims[1]: var.z_l})
      if debug: print(out)
      for i, rmask_field in enumerate(rmask_od.values()):
        out.values[i,:,:] = rmask_field

    return out

def HorizontalMeanDiff_da(var, dims=('yh', 'xh'), weights=None, basins=None, debug=False):
  """
  Wrapper for computing weighted horizontal mean difference (model - obs) for DataArrays.
  This function includes the option to provide Basins masks, which returns horizontal mean
  difference for each basin provided.

  Parameters
  ----------

  var : xarray.DataArray
    Difference between the actual values and predicted values (model - obs, or residual).

  dims : tuple, str
    Dimension(s) over which to apply average. Default is ('yh', 'xh').

  weights : xarray.DataArray
      weights to apply. It can be a masked array.

  basins : xarray.DataArray, optional
      Basins mask to apply. If True, returns horizontal mean difference for each basin provided.
      Basins must be generated by genBasinMasks. Default is False.

  debug : boolean, optional
    If true, print stuff for debugging. Default False

  Returns
  -------
  reduced : DataArray or DataSet
      If Basins is provided, returns an DataSet with horizontal mean difference. Otherwise,
       returns a DataArray.
  """
  check_dims(var,dims)
  if basins is not None and weights is None:
    raise ValueError("Basin masks can only be applied if weights are provided.")

  if weights is None:
    return  var.mean(dim=dims)
  else:
    rmask_od = OrderedDict()
    if basins is None:
      # global reduction
      if not isinstance(weights, xr.DataArray):
        raise ValueError("weights must be a DataArray")
      check_dims(weights,dims)
      total_weights = weights.sum(dim=dims)
      if debug: print('total weights is:', total_weights.values)
      out = mean_da(var, dims, weights=weights, weights_sum=total_weights)
      if debug: print('horizontal mean is:', out)
    else:
      # regional reduction
      if 'region' not in basins.coords:
        raise ValueError("Regions does not have coordinate region. Please use genBasinMasks \
                          to construct the basins mask.")
      if len(weights.shape)!=3:
        raise ValueError("If basins is provided, weights must be a 3D array.")

      if len(basins.shape)!=3:
        raise ValueError("Regions must be a 3D array.")

      for reg in basins.region:
        if debug: print('Region: ', reg)
        # construct a 3D region array
        tmp = np.repeat(basins.sel(region=reg).values[np.newaxis, :, :], len(var.z_l), axis=0)
        region3d = xr.DataArray(tmp,dims=var.dims[1::],
                                coords= {var.dims[1]: var.z_l,
                                         var.dims[2]: var.yh,
                                         var.dims[3]: var.xh})
        if debug: print('region3d:', region3d)
        # select weights to where region3d is one
        tmp_weights = weights.where(region3d == 1.0)
        total_weights = tmp_weights.sum(dim=dims)
        rmask_od[str(reg.values)] = mean_da(var, dims, weights=tmp_weights, weights_sum=total_weights)
        if debug: print('horizontal mean is:', rmask_od[str(reg.values)])
      # create dataArray to store rmask_od
      out = xr.DataArray(np.zeros((len(basins.region), var.shape[0], var.shape[1])),
                         dims=(basins.dims[0], var.dims[0], var.dims[1]),
                         coords={basins.dims[0]:list(rmask_od.keys()),
                                 var.dims[0]: var.time,
                                 var.dims[1]: var.z_l})

    for i, rmask_field in enumerate(rmask_od.values()):
      out.values[i,:,:] = rmask_field

    return out

def min_da(da, dims=('yh', 'xh')):
  """
  Calculates the minimun value in DataArray da,

  ----------
  da : xarray.DataArray
        DataArray for which to compute the min.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  Returns
  -------
  reduction : DataSet
      xarray.Dataset with min for da.
  """
  check_dims(da,dims)
  return da.min(dim=dims, keep_attrs=True)

def max_da(da, dims=('yh', 'xh')):
  """
  Calculates the maximum value in DataArray da.

  ----------
  da : xarray.DataArray
        DataArray for which to compute the max.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  Returns
  -------
  reduction : DataSet
      xarray.Dataset with the max for da.
  """
  check_dims(da,dims)
  return da.max(dim=dims, keep_attrs=True)

def mean_da(da, dims=('yh', 'xh'), weights=None,  weights_sum=None):
  """
  Calculates the mean value in DataArray da (optional weighted mean).

  ----------
  da : xarray.DataArray
        DataArray for which to compute (weighted) mean.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  weights : xarray.DataArray, optional
    weights to apply. It can be a masked array.

  weights_sum : xarray.DataArray, optional
    Total weight (i.e., weights.sum()). Only computed if not provided.

  Returns
  -------
  reduction : DataSet
      xarray.Dataset with (optionally weighted) mean for da.
  """
  check_dims(da,dims)
  if weights is not None:
    if weights_sum is None: weights_sum = weights.sum(dim=dims)
    out = ((da * weights).sum(dim=dims) / weights_sum)
    # copy attrs
    out.attrs = da.attrs
    return out
  else:
    return da.mean(dim=dims, keep_attrs=True)

def std_da(da, dims=('yh', 'xh'), weights=None,  weights_sum=None, da_mean=None):
  """
  Calculates the std in DataArray da (optional weighted std).

  ----------
  da : xarray.DataArray
        DataArray for which to compute (weighted) std.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  weights : xarray.DataArray, optional
    weights to apply. It can be a masked array.

  weights_sum : xarray.DataArray, optional
    Total weight (i.e., weights.sum()). Only computed if not provided.

  da_mean : xarray.DataArray, optional
   Mean value in DataArray da. Only computed if not provided.

  Returns
  -------
  reduction : DataSet
      xarray.Dataset with (optionally weighted) std for da.
  """

  check_dims(da,dims)
  if weights is not None:
    if weights_sum is None:
      weights_sum = weights.sum(dim=dims)
    if da_mean is None: da_mean = mean_da(da, dims, weights, weights_sum)
    out = np.sqrt(((da-da_mean)**2 * weights).sum(dim=dims)/weights_sum)
    # copy attrs
    out.attrs = da.attrs
    return out
  else:
    return da.std(dim=dims, keep_attrs=True)

def rms_da(da, dims=('yh', 'xh'), weights=None,  weights_sum=None):
  """
  Calculates the rms in DataArray da (optional weighted rms).

  ----------
  da : xarray.DataArray
        DataArray for which to compute (weighted) rms.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  weights : xarray.DataArray, optional
    weights to apply. It can be a masked array.

  weights_sum : xarray.DataArray, optional
    Total weight (i.e., weights.sum()). Only computed if not provided.

  Returns
  -------
  reduction : DataSet
      xarray.Dataset with (optionally weighted) rms for da.
  """

  check_dims(da,dims)
  if weights is not None:
    if weights_sum is None: weights_sum = weights.sum(dim=dims)
    out = np.sqrt((da**2 * weights).sum(dim=dims)/weights_sum)
    # copy attrs
    out.attrs = da.attrs
    return out
  else:
    return np.sqrt((da**2).mean(dim=dims, keep_attrs=True))

def check_dims(da,dims):
  """
  Checks if dims exists in ds.
  ----------
  da : xarray.DataArray
        DataArray for which to compute (weighted) min.

  dims : tuple, str
    Dimension(s) over which to apply reduction.
  """
  if dims[0] not in da.dims:
    print('dims[0], da.dims',dims[0], da.dims)
    raise ValueError("DataArray does not have dimensions given by dims[0]")
  if dims[1] not in da.dims:
    print('dims[1], da.dims',dims[1], da.dims)
    raise ValueError("DataArray does not have dimensions given by dims[1]")

  return

def myStats_da(da, weights, dims=('yh', 'xh'), basins=None, debug=False):
  """
  Calculates min, max, mean, standard deviation and root-mean-square for DataArray da
  and returns Dataset with values.

  Parameters
  ----------
  da : xarray.DataArray
        DataArray for which to compute weighted stats.

  dims : tuple, str
    Dimension(s) over which to apply reduction. Default is ('yh', 'xh').

  weights : xarray.DataArray
    weights to apply. It can be a masked array.

  basins : xarray.DataArray, optional
    Basins mask to apply. If True, returns horizontal mean RMSE for each basin provided. \
    Basins must be generated by genBasinMasks. Default is False.

  debug : boolean, optional
    If true, print stuff for debugging. Default is False.

  Returns
  -------
  reduced : DataSet
      New xarray.Dataset with min, max and weighted mean, standard deviation and
      root-mean-square for DataArray ds.
  """
  check_dims(da,dims)
  if weights is None:
    print('compute weights here')
    # compute weights here...

  rmask_od = OrderedDict()
  if basins is None:
    # global
    total_weights = weights.sum(dim=dims)
    da_min  = min_da(da, dims)
    da_max  = max_da(da, dims)
    da_mean = mean_da(da, dims, weights,  total_weights)
    da_std  = std_da(da, dims, weights,  total_weights, da_mean)
    da_rms  = rms_da(da, dims, weights,  total_weights)

    if debug: print_stats(da_min, da_max, da_mean, da_std, da_rms)

    out = stats_to_ds(da_min, da_max, da_mean, da_std, da_rms)
    # copy attrs
    out.attrs = da.attrs
    rmask_od['Global'] = out

  else:
    # aplpy reduction for each basin
    if 'region' not in basins.coords:
      raise ValueError("Regions does not have coordinate region. Please use genBasinMasks \
                        to construct the basins mask.")
    for reg in basins.region:
      if debug: print('Region: ', reg)
      # select region in the DataArray
      da_reg = da.where(basins.sel(region=reg).values == 1.0)
      # select weights to where region values are one
      tmp_weights = weights.where(basins.sel(region=reg).values == 1.0)
      total_weights = tmp_weights.sum(dim=dims)
      da_min  = min_da(da_reg , dims)
      da_max  = max_da(da_reg , dims)
      da_mean = mean_da(da_reg, dims, tmp_weights,  total_weights)
      da_std  = std_da(da_reg , dims, tmp_weights,  total_weights, da_mean)
      da_rms  = rms_da(da_reg , dims, tmp_weights,  total_weights)

      if debug:
        print_stats(da_min, da_max, da_mean, da_std, da_rms)

      out = stats_to_ds(da_min, da_max, da_mean, da_std, da_rms)
      rmask_od[str(reg.values)] = out

  return dict_to_da(rmask_od) # create dataarray using rmask_od

def print_stats(da_min, da_max, da_mean, da_std, da_rms):
  """
  Print values for debugging purposes.

  Parameters
  ----------

  da_* : xarray.DataArray
    DataArrays with min, max, std, mean, rms.
  """
  print('myStats: min(da) =' ,da_min)
  print('myStats: max(da) =' ,da_max)
  print('myStats: mean(da) =',da_mean)
  print('myStats: std(da) =' ,da_std)
  print('myStats: rms(da) =' ,da_rms)
  return

def stats_to_ds(da_min, da_max, da_mean, da_std, da_rms):
  """
  Creates a xarray.Dataset using DataArrays provided.

  Parameters
  ----------

  da_* : xarray.DataArray
    DataArrays with min, max, std, mean, rms.

  Returns
  -------
  ds : DataSet
      xarray.Dataset with min, max, mean, standard deviation and
      root-mean-square.
  """
  dim0 = da_min.dims[0]
  dim0_val = da_min[dim0]
  #if 'time' in da_min:
  #  var = np.zeros(len(da_min.time))
  #  time = da_mean['time']
  #else:
  #  var = np.zeros(1)
  #  time = np.array([0.])

  # create dataset with zeros
  ds = xr.Dataset(data_vars={ 'da_min' : ((dim0), da_min.data),
                              'da_max' : ((dim0), da_max.data),
                              'da_std' : ((dim0), da_std.data),
                              'da_rms' : ((dim0), da_rms.data),
                              'da_mean': ((dim0), da_mean.data)},
                   coords={dim0: dim0_val})
  # fill dataset with correct values
  #ds['da_mean'] = da_mean; ds['da_std'] = da_std; ds['da_rms'] = da_rms
  #ds['da_min'] = da_min; ds['da_max'] = da_max
  return ds

def dict_to_da(stats_dict):
  """
  Creates a xarray.DataArray using keys in dictionary (stats_dict).

  Parameters
  ----------

  stats_dict : OrderedDict
    Dictionary with statistics computed using function myStats_da

  Returns
  -------
  da : DataSet
      DataArray with min, max, mean, standard deviation and
      root-mean-square for different basins.
  """

  time = stats_dict[list(stats_dict.items())[0][0]].time
  basins = list(stats_dict.keys())
  stats = ['da_min', 'da_max', 'da_mean', 'da_std', 'da_rms']
  var = np.zeros((len(basins),len(stats),len(time)))
  da = xr.DataArray(var, dims=['basin', 'stats', 'time'],
                           coords={'basin': basins,
                                   'stats': stats,
                                   'time': time},)
  for reg in (basins):
    da.sel(basin=reg).sel(stats='da_min').values[:] = stats_dict[reg].da_min.values
    da.sel(basin=reg).sel(stats='da_max').values[:] = stats_dict[reg].da_max.values
    da.sel(basin=reg).sel(stats='da_mean').values[:]= stats_dict[reg].da_mean.values
    da.sel(basin=reg).sel(stats='da_std').values[:] = stats_dict[reg].da_std.values
    da.sel(basin=reg).sel(stats='da_rms').values[:] = stats_dict[reg].da_rms.values

  return da

def main(stream=False):

  # Get options
  args = options()

  # Read in the yaml file
  diag_config_yml = yaml.load(open(args.diag_config_yml_path,'r'), Loader=yaml.Loader)

  # Create the case instance
  dcase = DiagsCase(diag_config_yml['Case'], xrformat=True)
  DOUT_S = dcase.get_value('DOUT_S')
  if DOUT_S:
    OUTDIR = dcase.get_value('DOUT_S_ROOT')+'/ocn/hist/'
  else:
    OUTDIR = dcase.get_value('RUNDIR')

  print('Output directory is:', OUTDIR)
  print('Casename is:', dcase.casename)
  print('Number of workers: ', args.number_of_workers)

  args.z = dcase.casename+diag_config_yml['Fnames']['z']
  args.static = dcase.casename+diag_config_yml['Fnames']['static']

  if not os.path.isdir('PNG/Drift'):
    print('Creating a directory to place figures (PNG)... \n')
    os.system('mkdir -p PNG/Drift')
  if not os.path.isdir('ncfiles'):
    print('Creating a directory to place netCDF files (ncfiles)... \n')
    os.system('mkdir ncfiles')

  # read grid
  grd = MOM6grid(OUTDIR+'/'+args.static, xrformat=True)
  #grd = MOM6grid('ocean.mom6.static.nc', xrformat=True)
  try:
    area = np.ma.masked_where(grd.wet == 0,grd.area_t)
  except:
    area = np.ma.masked_where(grd.wet == 0,grd.areacello)

  try:
    depth = grd.depth_ocean.values
  except:
    depth = grd.deptho.values

  # Get masking for different regions
  # remove Nan's, otherwise genBasinMasks won't work
  depth[np.isnan(depth)] = 0.0
  basin_code = genBasinMasks(grd.geolon.values, grd.geolat.values, depth, xda=True)

  #select a few basins, namely, Global, MedSea,BalticSea,HudsonBay Arctic,
  # Pacific, Atlantic, Indian, Southern, LabSea and BaffinBay
  basins = basin_code.isel(region=[0,4,5,6,7,8,9,10,11,12,13])

  # load obs
  catalog = intake.open_catalog(diag_config_yml['oce_cat'])
  obs = catalog[args.obs].to_dask()[args.var]

  # diff_rms
  horizontal_mean_diff_rms(grd, dcase, basins, args, obs, OUTDIR)

  print('{} was run successfully!'.format(os.path.basename(__file__)))

  return


def horizontal_mean_diff_rms(grd, dcase, basins, args, obs, OUTDIR):
  '''
   Compute horizontal mean difference and rms: model versus observations.

   Parameters
  ----------

  grd : OrderedDict
    Dictionary with statistics computed using function myStats_da

  dcase : case object
    Object created using mom6_tools.DiagsCase.

  basins : DataArray
   Basins mask to apply. Returns horizontal mean RMSE for each basin provided.
   Basins must be generated by genBasinMasks.

  args : object
    Object with command line options.

  OUTDIR : str
    Path to the output.

  Returns
  -------
    Plots horizontal mean difference and rms for different basins.

  '''
  var = args.var
  try:
    area = grd.area_t.where(grd.wet > 0)
  except:
    area = grd.areacello.where(grd.wet > 0)

  if args.debug: print('OUTDIR:', OUTDIR)

  parallel = False
  if args.number_of_workers > 1:
    parallel = True
    cluster = NCARCluster()
    cluster.scale(args.number_of_workers)
    client = Client(cluster)

  def preprocess(ds):
    if 'thetao' not in ds.variables:
        ds["thetao"] = xr.zeros_like(ds.h)
    if 'so' not in ds.variables:
        ds["so"] = xr.zeros_like(ds.h)

    return ds

  # read dataset
  startTime = datetime.now()
  print('Reading dataset...')
  ds1 = xr.open_mfdataset(OUTDIR+'/'+args.z, parallel=parallel)
  ds = preprocess(ds1)

  if (var not in ds):
    raise ValueError("The variable requested is not available in the history files of this simulation. \
                     Only thetao and so are available at this time.")

  units = ds[var].units

  if args.debug:
    print(ds)

  print('Time elasped: ', datetime.now() - startTime)

  # Compute climatologies
  attrs =  {
         'description': 'Annual mean climatology for '+var,
         'reduction_method': 'annual mean weighted by days in each month',
         'casename': dcase.casename
         }

  model = weighted_temporal_mean(ds,var)

  # set coordinates to the same as the model's
  obs['xh'] = model.xh; obs['yh'] = model.yh;

  # compute difference
  diff = model - obs

  # construct a 3D area with land values masked
  area3d = np.repeat(area.values[np.newaxis, :, :], len(diff.z_l), axis=0)
  mask3d = xr.DataArray(area3d, dims=(diff.dims[1::]), coords= {diff.dims[1]: diff.z_l,
                                                                diff.dims[2]: diff.yh,
                                                                diff.dims[3]: diff.xh})
  area3d_masked = mask3d.where(diff[0,:] == diff[0,:])

  if args.drift:
    # Horizontal Mean difference (model - obs)
    description = 'Horizontal Mean drift for {}'.format(var)
    print('\n {}...'.format(description))
    startTime = datetime.now()
    vname = '{}_drift'.format(var)
    drift = HorizontalMeanDiff_da(diff,weights=area3d_masked, basins=basins, debug=args.debug).rename(vname)
    print('Time elasped: ', datetime.now() - startTime)

  if args.rms:
    # Horizontal Mean rms (model - obs)
    description = 'Horizontal RMSE for {}'.format(var)
    print('\n {}...'.format(description))
    startTime = datetime.now()
    vname = '{}_rms'.format(var)
    rms = HorizontalMeanRmse_da(diff,weights=area3d_masked, basins=basins, debug=args.debug).rename(vname)
    print('Time elasped: ', datetime.now() - startTime)

  if parallel:
    print('Releasing workers...')
    client.close(); cluster.close()

  print('Saving netCDF files...')
  attrs = {'casename': dcase.casename,
           'description': description,
           'obs': args.obs,
           'module': os.path.basename(__file__)}

  if args.drift:
    add_global_attrs(drift,attrs)
    drift.to_netcdf('ncfiles/'+str(dcase.casename)+'_{}_drift.nc'.format(var))

  if args.rms:
    add_global_attrs(rms,attrs)
    rms.to_netcdf('ncfiles/'+str(dcase.casename)+'_{}_rmse.nc'.format(var))

  if args.savefig:
    # save plots
    if args.drift:
      if var == 'thetao':
        clim_diff = (-3,3)
      else:
        clim_diff = (-1.5,1.5)

      print('Generating plots for {} drift...', str(var))
      for reg in drift.region:
        drift_reg = drift.sel(region=reg).dropna('z_l')
        if drift_reg.z_l.max() <= 1000.0:
          splitscale = None
        else:
          splitscale =  [0., -1000., -drift_reg.z_l.max()]

        savefig_diff='PNG/Drift/'+str(dcase.casename)+'_'+str(reg.values)+'_{}_drift.png'.format(var)
        vname = ', {} [{}], diff (model - obs)'.format(var,units)
        ztplot(drift_reg.values, drift_reg.time.values, drift_reg.z_l.values*-1, ignore=np.nan, splitscale=splitscale,
               suptitle=dcase._casename, contour=True, title= str(reg.values) + vname,
               extend='both', colormap='dunnePM', autocenter=True, tunits='Year', show=False, clim=clim_diff,
               save=savefig_diff, interactive=True);
        plt.close('all')

    if args.rms:
      if var == 'thetao':
        clim_rms = (0,6)
      else:
        clim_rms = (0,3)

      print('Generating plots for {} rms...', str(var))
      for reg in rms.region:
        rms_reg  = rms.sel(region=reg).dropna('z_l')
        if rms_reg.z_l.max() <= 1000.0:
          splitscale = None
        else:
          splitscale =  [0., -1000., -rms_reg.z_l.max()]

        savefig_rms='PNG/Drift/'+str(dcase.casename)+'_'+str(reg.values)+'_{}_rms.png'.format(var)
        vname = ', {} [{}], rms (model - obs)'.format(var,units)

        ztplot(rms_reg.values, rms_reg.time.values, rms_reg.z_l.values*-1, ignore=np.nan, splitscale=splitscale,
               suptitle=dcase._casename, contour=True, title= str(reg.values) + vname,
               extend='both', colormap='dunnePM', autocenter=False, tunits='Year', show=False, clim=clim_rms,
               save=savefig_rms, interactive=True);

        plt.close('all')
  return

if __name__ == '__main__':
  main()
